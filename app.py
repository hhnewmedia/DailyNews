import streamlit as st
import pandas as pd
from datetime import datetime
import feedparser
import io
import urllib.parse
import time

# --- 1. è¨­å®šèˆ‡ç¿»è­¯ ---
translations = {
    "ç¹é«”ä¸­æ–‡ (TW)": {
        "title": "é´»æµ·å…¨çƒè¼¿æƒ…ç›£æ§ç³»çµ±",
        "sidebar_title": "è¨­å®šé¢æ¿",
        "days_label": "æœå°‹æ™‚é–“ç¯„åœ (å¤©æ•¸)",
        "keywords_label": "è¼¸å…¥æœå°‹é—œéµå­— (å¤šçµ„è«‹ç”¨é€—è™Ÿéš”é–‹)",
        "keywords_hint": "å»ºè­°è¼¸å…¥: é´»æµ·, Foxconn, å¯Œå£«åº·, Fii, é´»è¯å…ˆé€²",
        "btn_start": "é–‹å§‹å…¨ç¶²æœå°‹",
        "download_btn": "ä¸‹è¼‰ Excel å ±è¡¨",
        "params": {"hl": "zh-TW", "gl": "TW", "ceid": "TW:zh-Hant"}
    },
    "English (US)": {
        "title": "Foxconn Media Monitor",
        "sidebar_title": "Settings",
        "days_label": "Search Range (Days)",
        "keywords_label": "Enter Keywords",
        "keywords_hint": "e.g., Foxconn, Fii, EV",
        "btn_start": "Start Search",
        "download_btn": "Download Excel",
        "params": {"hl": "en-US", "gl": "US", "ceid": "US:en"}
    },
    "Tiáº¿ng Viá»‡t (VN)": {
        "title": "Há»‡ thá»‘ng GiÃ¡m sÃ¡t Foxconn",
        "sidebar_title": "CÃ i Ä‘áº·t",
        "days_label": "Pháº¡m vi thá»i gian",
        "keywords_label": "Nháº­p tá»« khÃ³a",
        "keywords_hint": "VÃ­ dá»¥: Foxconn, Fii",
        "btn_start": "Báº¯t Ä‘áº§u tÃ¬m kiáº¿m",
        "download_btn": "Táº£i xuá»‘ng bÃ¡o cÃ¡o",
        "params": {"hl": "vi", "gl": "VN", "ceid": "VN:vi"}
    },
    "EspaÃ±ol (MX)": {
        "title": "Monitor Foxconn",
        "sidebar_title": "ConfiguraciÃ³n",
        "days_label": "Rango de tiempo",
        "keywords_label": "Palabras clave",
        "keywords_hint": "Ej: Foxconn, Fii",
        "btn_start": "Iniciar bÃºsqueda",
        "download_btn": "Descargar Excel",
        "params": {"hl": "es-419", "gl": "MX", "ceid": "MX:es-419"}
    },
    "PortuguÃªs (BR)": {
        "title": "Monitor Foxconn",
        "sidebar_title": "ConfiguraÃ§Ãµes",
        "days_label": "Intervalo de tempo",
        "keywords_label": "Palabras-chave",
        "keywords_hint": "Ex: Foxconn, Fii",
        "btn_start": "Iniciar pesquisa",
        "download_btn": "Baixar Excel",
        "params": {"hl": "pt-BR", "gl": "BR", "ceid": "BR:pt-419"}
    }
}

st.set_page_config(page_title="Foxconn Search Pro", layout="wide")

# Sidebar
language_option = st.sidebar.selectbox("Language / èªè¨€", list(translations.keys()))
t = translations[language_option]

st.title(f"ğŸ” {t['title']}")

st.sidebar.title(t['sidebar_title'])

# å¤©æ•¸æ»‘æ¡¿ (1-7å¤©)
days_selected = st.sidebar.slider(t['days_label'], 1, 7, 1)
time_param = f"when:{days_selected}d"

st.sidebar.markdown("---")
st.sidebar.info("ğŸ’¡ æç¤ºï¼šè¼¸å…¥è¶Šå¤šé—œéµå­—ï¼Œæœå°‹çµæœè¶Šå®Œæ•´ã€‚\nä¾‹å¦‚ï¼š`é´»æµ·, Foxconn, å¯Œå£«åº·`")

# --- 2. æ ¸å¿ƒæœå°‹å¼•æ“ (ç„¡é™åˆ¶ç‰ˆ) ---
def search_google_rss(keyword, time_limit, params):
    # Google News RSS URL
    base_url = "https://news.google.com/rss/search"
    query = f"{keyword} {time_limit}"
    encoded_query = urllib.parse.quote(query)
    
    # çµ„åˆ RSS ç¶²å€
    rss_url = f"{base_url}?q={encoded_query}&hl={params['hl']}&gl={params['gl']}&ceid={params['ceid']}"
    
    # è®€å– RSS
    feed = feedparser.parse(rss_url)
    
    results = []
    # ã€é—œéµä¿®æ”¹ã€‘é€™è£¡ä¸å†ä½¿ç”¨ [:10] é™åˆ¶ï¼Œæ”¹ç‚ºè®€å–æ‰€æœ‰ feed.entries
    for entry in feed.entries:
        # è™•ç†ç™¼å¸ƒæ™‚é–“æ ¼å¼
        if 'published_parsed' in entry:
            pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d %H:%M")
        else:
            pub_date = datetime.now().strftime("%Y-%m-%d %H:%M")

        results.append({
            "Date": pub_date,
            "Keyword": keyword,
            "Title": entry.title,
            "Source": entry.source.title if 'source' in entry else "Google News",
            "Link": entry.link
        })
    return results

# --- 3. ä¸»ç¨‹å¼ ---
user_keywords = st.text_input(t['keywords_label'], placeholder=t['keywords_hint'])

if st.button(t['btn_start'], type="primary"):
    if not user_keywords:
        st.error("âŒ è«‹è‡³å°‘è¼¸å…¥ä¸€å€‹é—œéµå­—")
    else:
        st.info("ğŸš€ å…¨ç¶²æœå°‹ä¸­ï¼Œè«‹ç¨å€™...")
        
        raw_news_list = []
        keywords_list = user_keywords.split(",")
        
        # é€²åº¦æ¢
        progress_bar = st.progress(0)
        total_kw = len(keywords_list)
        
        for idx, kw in enumerate(keywords_list):
            kw = kw.strip()
            if kw:
                results = search_google_rss(kw, time_param, t['params'])
                raw_news_list.extend(results)
            # æ›´æ–°é€²åº¦
            progress_bar.progress((idx + 1) / total_kw)
        
        if not raw_news_list:
            st.warning("âš ï¸ åœ¨æŒ‡å®šæ™‚é–“å…§æ‰¾ä¸åˆ°ç›¸é—œæ–°èã€‚å»ºè­°ï¼š\n1. å¢åŠ å¤©æ•¸ç¯„åœ\n2. å¢åŠ é—œéµå­— (å¦‚: Foxconn, å¯Œå£«åº·)")
        else:
            # è½‰ç‚º DataFrame
            df = pd.DataFrame(raw_news_list)
            
            # ã€é—œéµä¿®æ”¹ã€‘å»é‡åŠŸèƒ½
            # æœ‰æ™‚å€™ä¸åŒé—œéµå­—æœƒæœåˆ°åŒä¸€ç¯‡æ–°èï¼Œé€™è£¡ç”¨ã€Œé€£çµã€ä¾†å»é™¤é‡è¤‡
            initial_count = len(df)
            df = df.drop_duplicates(subset=['Link'])
            final_count = len(df)
            
            # æ’åºï¼šæŒ‰æ—¥æœŸç”±æ–°åˆ°èˆŠ
            df = df.sort_values(by='Date', ascending=False)
            
            # é¡¯ç¤ºçµ±è¨ˆ
            st.success(f"âœ… æœå°‹å®Œæˆï¼å…±æ‰¾åˆ° {final_count} ç¯‡æ–°è (å·²éæ¿¾é‡è¤‡ {initial_count - final_count} ç¯‡)")
            
            # é¡¯ç¤ºè¡¨æ ¼ (èª¿æ•´æ¬„ä½é †åº)
            cols = ["Date", "Keyword", "Title", "Source", "Link"]
            df = df[cols]
            
            # ä½¿ç”¨ container_width è®“è¡¨æ ¼å¡«æ»¿ç•«é¢ï¼Œä¸¦è¨­å®šé€£çµæ¬„ä½å¯é»æ“Š
            st.dataframe(
                df, 
                use_container_width=True,
                column_config={
                    "Link": st.column_config.LinkColumn("News Link")
                }
            )
            
            # ä¸‹è¼‰ Excel
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False)
                
            st.download_button(
                label=t['download_btn'],
                data=buffer,
                file_name=f"Foxconn_News_{datetime.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.ms-excel"
            )
